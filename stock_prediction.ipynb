{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/nChSjjvHVUcLk0VYsqEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReutFarkash/stocks/blob/master/stock_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhUGa2ImH-FP",
        "colab_type": "text"
      },
      "source": [
        "https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
        "How to Predict Stock Prices in Python using TensorFlow 2 and Keras\n",
        "Predicting different stock prices using Long Short-Term Memory Recurrent Neural Network in Python using TensorFlow 2 and Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgC3L4tXHsZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1afd038b-5bcf-481c-e0c4-d465cb3c94b9"
      },
      "source": [
        "!pip3 install tensorflow pandas numpy matplotlib yahoo_fin sklearn requests_html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: yahoo_fin in /usr/local/lib/python3.6/dist-packages (0.8.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: requests_html in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from requests_html) (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.0.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.2.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.6/dist-packages (from requests_html) (1.22.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.1.11)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.6/dist-packages (from requests_html) (1.4.1)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.6/dist-packages (from requests_html) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (49.6.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (1.25.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2020.6.20)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.48.2)\n",
            "Requirement already satisfied: pyee<8.0.0,>=7.0.1 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests_html) (7.0.3)\n",
            "Requirement already satisfied: websockets<9.0,>=8.1 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests_html) (8.1)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests_html) (1.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIBaeIbGIDlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqb7QhuoITpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seed, so we can get the same results after rerunning several times\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61NhYlGcIf0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    \"\"\"\n",
        "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
        "    Params:\n",
        "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
        "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
        "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
        "        shuffle (bool): whether to shuffle the data, default is True\n",
        "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
        "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
        "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
        "    \"\"\"\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    # train / test (TimeSeries) split\n",
        "    train_df, test_df = np.split(df, [int(len(df)*0.7)])\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            train_df[column] = scaler.fit_transform(np.expand_dims(train_df[column].values, axis=1))\n",
        "            test_df[column] = scaler.transform(np.expand_dims(test_df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    train_df['future'] = train_df['adjclose'].shift(-lookup_step)\n",
        "    test_df['future'] = test_df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence_train = np.array(train_df[feature_columns].tail(lookup_step))\n",
        "    last_sequence_test = np.array(test_df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    train_df.dropna(inplace=True)\n",
        "    sequence_data_train = []\n",
        "    sequences_train = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(train_df[feature_columns].values, train_df['future'].values):\n",
        "        sequences_train.append(entry)\n",
        "        if len(sequences_train) == n_steps:\n",
        "            sequence_data_train.append([np.array(sequences_train), target])\n",
        "    test_df.dropna(inplace=True)\n",
        "    sequence_data_test = []\n",
        "    sequences_test = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(test_df[feature_columns].values, test_df['future'].values):\n",
        "        sequences_test.append(entry)\n",
        "        if len(sequences_test) == n_steps:\n",
        "            sequence_data_test.append([np.array(sequences_test), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
        "    # this last_sequence will be used to predict future stock prices not available in the dataset\n",
        "    last_sequence_train = list(sequences_train) + list(last_sequence_train)\n",
        "    last_sequence_train = np.array(last_sequence_train)\n",
        "    # add to result\n",
        "    result['last_sequence_train'] = last_sequence_train\n",
        "    last_sequence_test = list(sequences_test) + list(last_sequence_test)\n",
        "    last_sequence_test = np.array(last_sequence_test)\n",
        "    # add to result\n",
        "    result['last_sequence_test'] = last_sequence_test\n",
        "    # construct the X's and y's\n",
        "    X_train, y_train = [], []\n",
        "    for seq, target in sequence_data_train:\n",
        "        X_train.append(seq)\n",
        "        y_train.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    # reshape X to fit the neural network\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[2], X_train.shape[1]))\n",
        "    # construct the X's and y's\n",
        "    X_test, y_test = [], []\n",
        "    for seq, target in sequence_data_train:\n",
        "        X_test.append(seq)\n",
        "        y_test.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    # reshape X to fit the neural network\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[2], X_test.shape[1]))\n",
        "    # split the dataset\n",
        "    p = np.random.permutation(len(X_train))\n",
        "    X_train = X_train[p]\n",
        "    y_train = y_train[p]\n",
        "    #idx = np.random.permutation(X_train.index)\n",
        "    #X_train.reindex(idx, inplace=True)\n",
        "    #Y_train.reindex(idx, inplace=True)\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = X_train, X_test, y_train, y_test\n",
        "    # return the result\n",
        "    return result"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym63baQlIgFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O3Sr0ACIg0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Window size or the sequence length\n",
        "N_STEPS = 70\n",
        "# Lookup step, 1 is the next day\n",
        "LOOKUP_STEP = 1\n",
        "# test ratio size, 0.2 is 20%\n",
        "TEST_SIZE = 0.2\n",
        "# features to use\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "# date now\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "### model parameters\n",
        "N_LAYERS = 3\n",
        "# LSTM cell\n",
        "CELL = LSTM\n",
        "# 256 LSTM neurons\n",
        "UNITS = 256\n",
        "# 40% dropout\n",
        "DROPOUT = 0.4\n",
        "# whether to use bidirectional RNNs\n",
        "BIDIRECTIONAL = False\n",
        "### training parameters\n",
        "# mean absolute error loss\n",
        "# LOSS = \"mae\"\n",
        "# huber loss\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "# Tesla stock market\n",
        "ticker = \"TSLA\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "# model name to save, making it as unique as possible based on parameters\n",
        "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wCfD5gzIhAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create these folders if they does not exist\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wf8vzdbIhIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a5def4f-4288-40b7-ba7e-549b08c93ee7"
      },
      "source": [
        "# load the data\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "# save the dataframe\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "# some tensorflow callbacks\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)\n",
        "model.save(os.path.join(\"results\", model_name) + \".h5\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.3602WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            " 2/27 [=>............................] - ETA: 0s - loss: 0.0623 - mean_absolute_error: 0.2541WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0139s vs `on_train_batch_end` time: 0.0600s). Check your callbacks.\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 0.0122 - mean_absolute_error: 0.1061\n",
            "Epoch 00001: val_loss improved from inf to 0.00282, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 1s 44ms/step - loss: 0.0110 - mean_absolute_error: 0.1001 - val_loss: 0.0028 - val_mean_absolute_error: 0.0548\n",
            "Epoch 2/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0598\n",
            "Epoch 00002: val_loss improved from 0.00282 to 0.00255, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0038 - mean_absolute_error: 0.0600 - val_loss: 0.0025 - val_mean_absolute_error: 0.0484\n",
            "Epoch 3/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0556\n",
            "Epoch 00003: val_loss improved from 0.00255 to 0.00241, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0033 - mean_absolute_error: 0.0554 - val_loss: 0.0024 - val_mean_absolute_error: 0.0470\n",
            "Epoch 4/50\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0566\n",
            "Epoch 00004: val_loss improved from 0.00241 to 0.00195, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0033 - mean_absolute_error: 0.0555 - val_loss: 0.0020 - val_mean_absolute_error: 0.0434\n",
            "Epoch 5/50\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0518\n",
            "Epoch 00005: val_loss improved from 0.00195 to 0.00180, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0028 - mean_absolute_error: 0.0516 - val_loss: 0.0018 - val_mean_absolute_error: 0.0434\n",
            "Epoch 6/50\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0502\n",
            "Epoch 00006: val_loss did not improve from 0.00180\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0027 - mean_absolute_error: 0.0503 - val_loss: 0.0020 - val_mean_absolute_error: 0.0415\n",
            "Epoch 7/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0500\n",
            "Epoch 00007: val_loss improved from 0.00180 to 0.00178, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_error: 0.0494 - val_loss: 0.0018 - val_mean_absolute_error: 0.0436\n",
            "Epoch 8/50\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0478\n",
            "Epoch 00008: val_loss improved from 0.00178 to 0.00119, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0024 - mean_absolute_error: 0.0466 - val_loss: 0.0012 - val_mean_absolute_error: 0.0343\n",
            "Epoch 9/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0454\n",
            "Epoch 00009: val_loss improved from 0.00119 to 0.00113, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0023 - mean_absolute_error: 0.0455 - val_loss: 0.0011 - val_mean_absolute_error: 0.0337\n",
            "Epoch 10/50\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0399\n",
            "Epoch 00010: val_loss improved from 0.00113 to 0.00097, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0017 - mean_absolute_error: 0.0398 - val_loss: 9.6634e-04 - val_mean_absolute_error: 0.0299\n",
            "Epoch 11/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0383\n",
            "Epoch 00011: val_loss improved from 0.00097 to 0.00089, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0016 - mean_absolute_error: 0.0381 - val_loss: 8.8580e-04 - val_mean_absolute_error: 0.0283\n",
            "Epoch 12/50\n",
            "21/27 [======================>.......] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0362\n",
            "Epoch 00012: val_loss improved from 0.00089 to 0.00073, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.0015 - mean_absolute_error: 0.0365 - val_loss: 7.2660e-04 - val_mean_absolute_error: 0.0261\n",
            "Epoch 13/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0367\n",
            "Epoch 00013: val_loss improved from 0.00073 to 0.00068, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.0015 - mean_absolute_error: 0.0365 - val_loss: 6.7980e-04 - val_mean_absolute_error: 0.0255\n",
            "Epoch 14/50\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0372\n",
            "Epoch 00014: val_loss did not improve from 0.00068\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0015 - mean_absolute_error: 0.0372 - val_loss: 6.9222e-04 - val_mean_absolute_error: 0.0255\n",
            "Epoch 15/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0335\n",
            "Epoch 00015: val_loss improved from 0.00068 to 0.00046, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0012 - mean_absolute_error: 0.0333 - val_loss: 4.6199e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 16/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0340\n",
            "Epoch 00016: val_loss did not improve from 0.00046\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0013 - mean_absolute_error: 0.0345 - val_loss: 0.0012 - val_mean_absolute_error: 0.0354\n",
            "Epoch 17/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0383\n",
            "Epoch 00017: val_loss did not improve from 0.00046\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0016 - mean_absolute_error: 0.0380 - val_loss: 9.3129e-04 - val_mean_absolute_error: 0.0300\n",
            "Epoch 18/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0310\n",
            "Epoch 00018: val_loss did not improve from 0.00046\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - mean_absolute_error: 0.0311 - val_loss: 4.9133e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 19/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0331\n",
            "Epoch 00019: val_loss improved from 0.00046 to 0.00042, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0012 - mean_absolute_error: 0.0329 - val_loss: 4.2183e-04 - val_mean_absolute_error: 0.0199\n",
            "Epoch 20/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0306\n",
            "Epoch 00020: val_loss improved from 0.00042 to 0.00029, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.0010 - mean_absolute_error: 0.0304 - val_loss: 2.9219e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 21/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0310\n",
            "Epoch 00021: val_loss improved from 0.00029 to 0.00027, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - mean_absolute_error: 0.0309 - val_loss: 2.7084e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 22/50\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0316\n",
            "Epoch 00022: val_loss did not improve from 0.00027\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0011 - mean_absolute_error: 0.0316 - val_loss: 7.7903e-04 - val_mean_absolute_error: 0.0284\n",
            "Epoch 23/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 9.9909e-04 - mean_absolute_error: 0.0299\n",
            "Epoch 00023: val_loss did not improve from 0.00027\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.7959e-04 - mean_absolute_error: 0.0296 - val_loss: 3.0680e-04 - val_mean_absolute_error: 0.0175\n",
            "Epoch 24/50\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 8.6060e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00024: val_loss did not improve from 0.00027\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 9.2114e-04 - mean_absolute_error: 0.0292 - val_loss: 8.4555e-04 - val_mean_absolute_error: 0.0291\n",
            "Epoch 25/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0303    \n",
            "Epoch 00025: val_loss did not improve from 0.00027\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.0010 - mean_absolute_error: 0.0305 - val_loss: 4.2775e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 26/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 9.1914e-04 - mean_absolute_error: 0.0292\n",
            "Epoch 00026: val_loss did not improve from 0.00027\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 8.9477e-04 - mean_absolute_error: 0.0288 - val_loss: 3.8476e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 27/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 7.8213e-04 - mean_absolute_error: 0.0265\n",
            "Epoch 00027: val_loss improved from 0.00027 to 0.00024, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.7566e-04 - mean_absolute_error: 0.0265 - val_loss: 2.4100e-04 - val_mean_absolute_error: 0.0150\n",
            "Epoch 28/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 8.2345e-04 - mean_absolute_error: 0.0274\n",
            "Epoch 00028: val_loss improved from 0.00024 to 0.00024, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 8.4356e-04 - mean_absolute_error: 0.0278 - val_loss: 2.3574e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 29/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 8.5186e-04 - mean_absolute_error: 0.0279\n",
            "Epoch 00029: val_loss improved from 0.00024 to 0.00022, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 16ms/step - loss: 8.2886e-04 - mean_absolute_error: 0.0275 - val_loss: 2.2227e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 30/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 8.2191e-04 - mean_absolute_error: 0.0271\n",
            "Epoch 00030: val_loss did not improve from 0.00022\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 8.1584e-04 - mean_absolute_error: 0.0270 - val_loss: 2.2570e-04 - val_mean_absolute_error: 0.0149\n",
            "Epoch 31/50\n",
            "23/27 [========================>.....] - ETA: 0s - loss: 7.7543e-04 - mean_absolute_error: 0.0272\n",
            "Epoch 00031: val_loss did not improve from 0.00022\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.5863e-04 - mean_absolute_error: 0.0269 - val_loss: 2.9479e-04 - val_mean_absolute_error: 0.0170\n",
            "Epoch 32/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 7.9303e-04 - mean_absolute_error: 0.0268\n",
            "Epoch 00032: val_loss improved from 0.00022 to 0.00022, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.7895e-04 - mean_absolute_error: 0.0265 - val_loss: 2.1805e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 33/50\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 6.8951e-04 - mean_absolute_error: 0.0255\n",
            "Epoch 00033: val_loss improved from 0.00022 to 0.00020, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 7.2552e-04 - mean_absolute_error: 0.0260 - val_loss: 2.0400e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 34/50\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 7.7742e-04 - mean_absolute_error: 0.0268\n",
            "Epoch 00034: val_loss did not improve from 0.00020\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 7.8376e-04 - mean_absolute_error: 0.0268 - val_loss: 2.7796e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 6.7139e-04 - mean_absolute_error: 0.0247\n",
            "Epoch 00035: val_loss did not improve from 0.00020\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.7139e-04 - mean_absolute_error: 0.0247 - val_loss: 2.2055e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 36/50\n",
            "22/27 [=======================>......] - ETA: 0s - loss: 7.0527e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00036: val_loss did not improve from 0.00020\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9980e-04 - mean_absolute_error: 0.0255 - val_loss: 2.1516e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 37/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 7.0554e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00037: val_loss did not improve from 0.00020\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 7.0470e-04 - mean_absolute_error: 0.0256 - val_loss: 2.2192e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 38/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 6.5750e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 00038: val_loss did not improve from 0.00020\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.9191e-04 - mean_absolute_error: 0.0256 - val_loss: 2.2256e-04 - val_mean_absolute_error: 0.0153\n",
            "Epoch 39/50\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 8.2918e-04 - mean_absolute_error: 0.0281\n",
            "Epoch 00039: val_loss improved from 0.00020 to 0.00020, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.2282e-04 - mean_absolute_error: 0.0280 - val_loss: 2.0142e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 40/50\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 6.7363e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00040: val_loss did not improve from 0.00020\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 6.7315e-04 - mean_absolute_error: 0.0252 - val_loss: 2.4462e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 8.8056e-04 - mean_absolute_error: 0.0281\n",
            "Epoch 00041: val_loss improved from 0.00020 to 0.00019, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 8.8056e-04 - mean_absolute_error: 0.0281 - val_loss: 1.9200e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 42/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 8.8237e-04 - mean_absolute_error: 0.0286\n",
            "Epoch 00042: val_loss did not improve from 0.00019\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 8.7976e-04 - mean_absolute_error: 0.0286 - val_loss: 7.0897e-04 - val_mean_absolute_error: 0.0274\n",
            "Epoch 43/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 7.0852e-04 - mean_absolute_error: 0.0260\n",
            "Epoch 00043: val_loss did not improve from 0.00019\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.0450e-04 - mean_absolute_error: 0.0259 - val_loss: 2.5351e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 44/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 7.1667e-04 - mean_absolute_error: 0.0261\n",
            "Epoch 00044: val_loss did not improve from 0.00019\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 7.0446e-04 - mean_absolute_error: 0.0260 - val_loss: 2.3919e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 45/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 6.2569e-04 - mean_absolute_error: 0.0247\n",
            "Epoch 00045: val_loss did not improve from 0.00019\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 6.4018e-04 - mean_absolute_error: 0.0250 - val_loss: 2.7838e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 46/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 6.6389e-04 - mean_absolute_error: 0.0249\n",
            "Epoch 00046: val_loss did not improve from 0.00019\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 6.6006e-04 - mean_absolute_error: 0.0248 - val_loss: 1.9861e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 47/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 6.0541e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00047: val_loss improved from 0.00019 to 0.00019, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 5.8284e-04 - mean_absolute_error: 0.0234 - val_loss: 1.9091e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 48/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 5.8086e-04 - mean_absolute_error: 0.0233\n",
            "Epoch 00048: val_loss improved from 0.00019 to 0.00018, saving model to results/2020-09-05_TSLA-huber_loss-adam-LSTM-seq-70-step-1-layers-3-units-256.h5\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 6.0234e-04 - mean_absolute_error: 0.0236 - val_loss: 1.8414e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 49/50\n",
            "25/27 [==========================>...] - ETA: 0s - loss: 6.1331e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00049: val_loss did not improve from 0.00018\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 6.0707e-04 - mean_absolute_error: 0.0237 - val_loss: 1.9849e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 50/50\n",
            "24/27 [=========================>....] - ETA: 0s - loss: 6.0300e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00050: val_loss did not improve from 0.00018\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 5.9891e-04 - mean_absolute_error: 0.0244 - val_loss: 2.5734e-04 - val_mean_absolute_error: 0.0163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqsXVKByIhL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tensorboard --logdir=\"logs\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtuACy80Ifls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WktsruRJEqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87fe6e29-3215-45d0-d7de-c84591e03f90"
      },
      "source": [
        "# evaluate the model\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "# calculate the mean absolute error (inverse scaling)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 4.355269626299664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8bOVCc8JEtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, data, on='_train'):\n",
        "    # retrieve the last sequence from data\n",
        "    last_sequence = data[\"last_sequence\" + on][-N_STEPS:]\n",
        "    # retrieve the column scalers\n",
        "    column_scaler = data[\"column_scaler\"]\n",
        "    # reshape the last sequence\n",
        "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
        "    # expand dimension\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "    # get the prediction (scaled from 0 to 1)\n",
        "    prediction = model.predict(last_sequence)\n",
        "    # get the price (by inverting the scaling)\n",
        "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    return predicted_price"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjpaTfziJEwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b155642f-5825-4984-838f-5bbadc91f5c6"
      },
      "source": [
        "# predict the future price\n",
        "future_price = predict(model, data)\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 1 days is 71.73$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNL7Uw3yJEzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    # last 200 days, feel free to edit that\n",
        "    plt.plot(y_test[-200:], c='b')\n",
        "    plt.plot(y_pred[-200:], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXOZJLGdJE2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c0edec56-5341-48d3-e187-56afa1790000"
      },
      "source": [
        "plot_graph(model, data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GkuKm1JJRK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
        "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
        "    return accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eftki4C0JRNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "799e77fb-7d19-497f-f2eb-5c7f7a245165"
      },
      "source": [
        "print(str(LOOKUP_STEP) + \":\", \"Accuracy Score:\", get_accuracy(model, data))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: Accuracy Score: 0.504927536231884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFurwh0YJRQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh9QJm_ZJRTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llp_ZvUWJRWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}